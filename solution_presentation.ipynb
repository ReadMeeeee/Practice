{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Практика\n",
    "\n",
    "## Задача\n",
    "\n",
    "Есть переписка ТП с пользователем.\n",
    "Переписка содержит все данные по решению инцидента\n",
    "- описание и уточнение проблемы,\n",
    "- обсуждение вариантов решения,\n",
    "- итоговое решение\n",
    "\n",
    "На основе переписки формировать два текста:\n",
    "1. краткое описание проблемы (возможно, с выделением ключевых слов),\n",
    "2. шаги решения (инструкция).\n",
    "\n",
    "Будет использоваться механизм поиска похожих обращений (по описанию проблемы)\n",
    "\n",
    "## Ожидаемое решение\n",
    "\n",
    "Функция принимающая на вход `.docx`-файлы, и возвращающая массив решений (и пусть директорию решений в `.txt`-файлах)."
   ],
   "id": "944e57bc8df88fb9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Этапы решения задачи.\n",
    "\n",
    "### 1. Загрузка `.docx`-документов.\n",
    "\n",
    "Используя библиотеку `python-docx` для обработки Word-документов, описана функция `load_docx_from_project(path)` для гибкой загрузки всех `.docx`-файлов из заданной директории, от моментального форматирования в класс `Chat` отказался в пользу масштабируемости, чтобы на руках были сырые данные.\n",
    "\n",
    "### 2. Представление и формат данных.\n",
    "\n",
    "Данные в переписке представлены как таблицы с колонками:\n",
    "- Номер обращения\n",
    "- Отправитель\n",
    "- Текст сообщения\n",
    "\n",
    "Решение строится на 3х ключевых классах:\n",
    "\n",
    "- `Message`: инкапсулирует отправителя и текст.\n",
    "- `Chat`: объединяет список сообщений и метаданные (название, номера обращений).\n",
    "- `CompanyChat`: содержит очищенный текст чата, готовый к отправке в ИИ.\n",
    "\n",
    "**Плюсы:**\n",
    "- Чёткое разделение областей ответственности.\n",
    "- Упрощает последующую обработку данных.\n",
    "- Повышает читаемость и поддержку кода.\n",
    "Отсюда вытекает небольшой выигрыш в гибкости и мобильности кода.\n",
    "\n",
    "### 3. Очистка и нормализация текста.\n",
    "\n",
    "Перед обработкой ИИ, данные проходят классическую фильтрацию:\n",
    "- Удаление спецсимволов.\n",
    "- Очистка пустых строк.\n",
    "- Приведение регистра (опционально).\n",
    "\n",
    "\n",
    "### 4. Подготовка промптов для ИИ.\n",
    "\n",
    "Для каждого типа запроса формируется `LLMRequest` на базе `InstructionBlock`, который в свою очередь будет формироваться из `.json`-файла содержащего:\n",
    "- Роль (например: \"Ты — ассистент, анализирующий переписку...\")\n",
    "- Инструкцию\n",
    "- Контекст (например, список аббревиатур)\n",
    "- Формат ответа\n",
    "- `max_tokens` — ограничение длины ответа\n",
    "Такой подход должен обеспечить возможность к будущему расширению и простоте управления (исправления).\n",
    "\n",
    "### 5. Отправка запроса и обработка со стороны ИИ.\n",
    "\n",
    "Создается запрос к заданному ИИ с инструктивным промптом к задаче. Использован `ThreadPoolExecutor`, чтобы одновременно отправлять три запроса:\n",
    "- Краткое описание\n",
    "- Ключевые слова\n",
    "- Решение проблемы\n",
    "Выбор пал именно на `ThreadPoolExecutor` так как в отличии, например, от `Threading` дает простое управление потоками, и главное - его не блокирует GIL, так как выполняются операции I/O.\n",
    "\n",
    "**Плюсы:**\n",
    "- Экономия времени при большом числе файлов.\n",
    "- Возможность легко отключить параллельность для отладки (флаг `multi_thread`).\n",
    "\n",
    "### 6. Сохранение результатов и финальная обертка.\n",
    "\n",
    "После обработки создаётся объект `ProblemWithSolution`, в который входят:\n",
    "- Название компании\n",
    "- Краткое описание\n",
    "- Ключевые слова\n",
    "- Инструкция\n",
    "\n",
    "Отдельно от `.ipynb`-решения создам модуль, с функцией, который будет на вход получать директорию и возвращать директорию с `.txt` решениями.\n",
    "\n",
    "## Заключение.\n",
    "\n",
    "Так как задача оказалось достаточно простой, я прибегнул к упрощению и оптимизации отдельных фрагментов. Таким образом удалось достичь:\n",
    "- **Гибкости**: в код достаточно много разделений на отдельный элементы, классы или функции, что позволит адаптировать под новые задачи.\n",
    "- **Масштабируемости**: реализация сразу предполагает работу как с одним документом, так и с массивом.\n",
    "- **Поддержки повторного использования**: структуры `InstructionBlock`, `LLMRequest`, `Chat`, `CompanyChat` легко масштабируются и тестируются.\n",
    "- **Расширяемости**: добавление новых типов инструкций (например, тональность, оценка качества и т.п) - это лишь вопрос дополнительных полей инструкции."
   ],
   "id": "98b7d12e32d1677"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Начало работы\n",
    "- Из директории ```input_data```, содержащую в себе .docx файлы, необходимо извлечь данные.\n",
    "- С извлечением поможет библиотека ```python_docx```.\n",
    "- Для извлечения опишу функцию, которая вернет сырые данные (возможно пригодится в плане гибкости)."
   ],
   "id": "9ffd3f566b532893"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:27:16.874883Z",
     "start_time": "2025-05-12T11:27:15.838366Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install python-docx",
   "id": "517a8bc17d59b5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from python-docx) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from python-docx) (4.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:27:16.953277Z",
     "start_time": "2025-05-12T11:27:16.886621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from os import listdir, path\n",
    "from docx import Document\n",
    "\n",
    "\n",
    "def load_docx_from_project(path_in_project='input_data/'):\n",
    "    documents = []\n",
    "\n",
    "    for filename in listdir(path_in_project):\n",
    "        if filename.endswith('.docx'):\n",
    "            full_path = path.join(path_in_project, filename)\n",
    "            try:\n",
    "                document = Document(full_path)\n",
    "                documents.append([filename, document])\n",
    "            except Exception as e:\n",
    "                print(f\"Не удалось загрузить {filename}: {e}\")\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Извлечение данных из файлов .docx\n",
    "docs = load_docx_from_project()\n"
   ],
   "id": "33fd21418cee50e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Обработка входных данных\n",
    "- Входные данные представлены в формате .docx -> их извлечение дает свой особый формат.\n",
    "- Необходимо обработать данные путем прохода по строкам и столбцам таблицы. Также нужно очистить данные от мусора для ИИ.\n",
    "- Для обработки следует создать 3 класса: Message, Chat и Company_Chat:\n",
    "    - Message хранит в себе отправитель сообщения и его текст.\n",
    "    - Chat содержит в себе массив Messageй, имя компании, и номера обращений (возможно понадобятся в плане гибкости).\n",
    "    - CompanyChat - очищенный чат с компанией (название, переписка).\n",
    "- После обработки хорошим решением кажется создания директории очищенных .txt файлов."
   ],
   "id": "34b60c7ceb302418"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Создание классов ```Message```, ```Chat```, ```Company_Chat```.",
   "id": "5d48278cb7e465c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:27:16.968104Z",
     "start_time": "2025-05-12T11:27:16.964404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    sender: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Chat:\n",
    "    messages: list[Message]\n",
    "    name: str = None\n",
    "    numbers: list[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CompanyChat:\n",
    "    company: str\n",
    "    whole_chat: str\n"
   ],
   "id": "712007a1246bb310",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Конвертация данных из .docx в Chat.",
   "id": "1c1604b84e70ba00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:27:17.033031Z",
     "start_time": "2025-05-12T11:27:16.977933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_from_docx(document: tuple[str, Document]):\n",
    "    name = document[0][:-5]\n",
    "\n",
    "    table = document[1].tables[0]\n",
    "    numbers: list[str] = []\n",
    "    messages: list[Message] = []\n",
    "    for row in table.rows[1:]:\n",
    "        cells = row.cells\n",
    "        message = Message(cells[1].text, cells[2].text)\n",
    "\n",
    "        numbers.append(cells[0].text)\n",
    "        messages.append(message)\n",
    "    numbers = set(numbers)\n",
    "\n",
    "    chat = Chat(\n",
    "        name=name,\n",
    "        numbers=numbers,\n",
    "        messages=messages\n",
    "    )\n",
    "    '''\n",
    "    print(f\"|{'Компания':<16}|\", chat.name,\n",
    "          f\"\\n|{'№ обращений':<16}|\", chat.numbers,\n",
    "          f\"\\n|{'Отправитель':<16}|\", chat.messages[0].sender,\n",
    "          f\"\\n|{'Текст сообщения':<16}|\\n\", chat.messages[0].text)\n",
    "    '''\n",
    "    return chat\n",
    "\n",
    "\n",
    "# Изменение типа переменных\n",
    "chats: list[Chat] = []\n",
    "for doc in docs:\n",
    "    chat = convert_from_docx(doc)\n",
    "    chats.append(chat)\n"
   ],
   "id": "e30f27a245f4eff3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Очистка Chatов, сохранение в массив CompanyChat.",
   "id": "49c0fbb08e7d2c9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:27:17.054940Z",
     "start_time": "2025-05-12T11:27:17.045349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from re import sub\n",
    "\n",
    "\n",
    "REMOVE_CHARS = {\n",
    "    0x00A0: None,  # NBSP – неразрывный пробел\n",
    "    0x00AD: None,  # SHY – мягкий перенос\n",
    "    0x200B: None,  # ZWSP – нулевой пробел\n",
    "    0xFEFF: None   # BOM – метка порядка байтов\n",
    "}\n",
    "\n",
    "\n",
    "def clear_text(\n",
    "    text: str,\n",
    "    symbols_to_remove: dict[int, None],\n",
    "    to_lower: bool = False,\n",
    "    normalize_spaces: bool = True\n",
    ") -> str:\n",
    "    text = text.translate(symbols_to_remove)\n",
    "    text = sub(r'\\n+', '\\n', text)\n",
    "    text = sub(r'[ \\t]+\\n', '\\n', text)\n",
    "\n",
    "    if normalize_spaces:\n",
    "        text = sub(r'[ \\t]{2,}', ' ', text)\n",
    "\n",
    "    text = \"\\n\".join(line.strip() for line in text.splitlines())\n",
    "\n",
    "    if to_lower:\n",
    "        text = text.lower()\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def format_chat(chat: Chat) -> CompanyChat:\n",
    "    dialog = \"\"\n",
    "\n",
    "    for message in chat.messages:\n",
    "        cleared_text = clear_text(message.text, REMOVE_CHARS)\n",
    "        dialog += (message.sender + ': ' + '\\n' +\n",
    "                   cleared_text + '\\n\\n')\n",
    "\n",
    "    name_data = CompanyChat(chat.name, dialog)\n",
    "    return name_data\n",
    "\n",
    "\n",
    "texts_to_process: list[CompanyChat] = []\n",
    "for chat in chats:\n",
    "    texts_to_process.append(format_chat(chat))\n"
   ],
   "id": "19083d80bd2f4f50",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Подготовка директории и загрузка в нее готовых данных.",
   "id": "e2d931172e80091d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:27:17.071363Z",
     "start_time": "2025-05-12T11:27:17.067443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from os import makedirs\n",
    "\n",
    "\n",
    "def ensure_folder_exists(folder_path: str = \"to_process\") -> None:\n",
    "    makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "\n",
    "def write_text_to_file(\n",
    "    data: CompanyChat,\n",
    "    folder_path: str = \"to_process\"\n",
    ") -> None:\n",
    "    file_path = folder_path + '/' + data.company + \".txt\"\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(data.whole_chat)\n",
    "\n",
    "\n",
    "ensure_folder_exists()\n",
    "for data in texts_to_process:\n",
    "    write_text_to_file(data)\n"
   ],
   "id": "87b8e12ee34477cf",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Основной фрагмент\n",
    "Данные очищены, отформатированы и лежат на низком старте. Для их обработки нужно формировать запросы к ИИ. Запросы будут формироваться из инструкций и переписки с ТП. Для всего озвученного целесообразно снова прибегнуть к классам:\n",
    "- ```InstructionBlock```    - составной блок инструкций для ИИ;\n",
    "- ```LLMRequest```          - запрос из инструкций и задачи;\n",
    "- ```AIModelAPI```          - API к модели ИИ;\n",
    "- ```ProblemWithSolutin```  - данные на выход (компания, краткое описание проблемы, ключевые слова, структурированное решение).\n",
    "\n",
    "Решение будет разбито на пару шагов:\n",
    "- До отправки запрос пройдет фазу сборки из инструкции и текста чата. Формирование инструкции лучше всего производить через .json файл, такой подход:\n",
    "     - Увеличивает мобильность и гибкость кода.\n",
    "     - Упрощает коррекцию инструкций.\n",
    "     - Уменьшает и упрощает код.\n",
    "\n",
    "- По API будут параллельно отправлены 3 запроса к ИИ (DeepSeek V3/ ChatGPT 4 turbo):\n",
    "    - Формирование краткого описания проблемы.\n",
    "    - Извлечение ключевых слов.\n",
    "    - Поиск и создание решения.\n",
    "\n",
    "- Переменные класса ProblemWithSolution будут сформированы из названия файла, хранящего переписку с ТП, и из ответов на запросы."
   ],
   "id": "9a635759da6fae1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Создание классов - ```InstructionBlock```, ```LLMRequest```, ```AIModelAPI```, ```ProblemWithSolutin```.",
   "id": "a0ff5498e4ca7d2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:27:17.995911Z",
     "start_time": "2025-05-12T11:27:17.086575Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install openai",
   "id": "de760091cc6825ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (1.77.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\pycharmprojects\\pratctice\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:27:18.433625Z",
     "start_time": "2025-05-12T11:27:18.007462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from json import load\n",
    "from dataclasses import dataclass\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InstructionBlock:\n",
    "    role: str\n",
    "    instruction: str\n",
    "    context: str\n",
    "    format: str | None\n",
    "    max_tokens: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LLMRequest:\n",
    "    instruction_block: InstructionBlock\n",
    "    task: str\n",
    "\n",
    "    def to_prompt(self) -> list[dict[str, str]]:\n",
    "        prompt = (\n",
    "            f\"{self.instruction_block.instruction}\\n\\n\"\n",
    "            f\"Контекст:\\n{self.instruction_block.context}\\n\\n\"\n",
    "            f\"Формат вывода:\\n{self.instruction_block.format}\\n\\n\"\n",
    "            f\"Ограничение по токенам:\\n{self.instruction_block.max_tokens}\\n\\n\"\n",
    "            f\"Входные данные:\\n{self.task}\"\n",
    "        )\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": self.instruction_block.role},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def max_tokens(self) -> int:\n",
    "        return self.instruction_block.max_tokens\n",
    "\n",
    "\n",
    "class AIModelAPI:\n",
    "    def __init__(self, api: str, url: str, model_name: str):\n",
    "        self.api = api\n",
    "        self.url = url\n",
    "        self.model_name = model_name\n",
    "        self.client = OpenAI(api_key=self.api, base_url=self.url)\n",
    "\n",
    "    def get_response(self, request: LLMRequest,\n",
    "                     max_tokens: int = 50, temperature: float = 0.1):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=request.to_prompt(),\n",
    "            stream=False,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ProblemWithSolution:\n",
    "        description: str\n",
    "        keywords: list[str]\n",
    "        solution: str\n",
    "        name: str = \"untitled\"\n",
    "        numbers: list[str] = None\n"
   ],
   "id": "f1bbac90040e184a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Извлечение данных .txt, .json (переписки ТП, конфигурация инструкций). Формирование инструкций.",
   "id": "fc66b6317ad63737"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:27:18.464573Z",
     "start_time": "2025-05-12T11:27:18.460817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(instruction_path: str) -> str:\n",
    "    with open(instruction_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def load_instruction_file(json_path: str):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = load(f)\n",
    "\n",
    "    abbreviations = \"\\n\".join(data[\"context\"])\n",
    "    role = data[\"role\"]\n",
    "\n",
    "    def make_instruction(key: str) -> InstructionBlock:\n",
    "        item = data[\"instructions\"][key]\n",
    "        return InstructionBlock(\n",
    "            role=role,\n",
    "            instruction=item[\"instruction\"],\n",
    "            context=abbreviations,\n",
    "            format=item[\"response_format\"],\n",
    "            max_tokens=item[\"max_tokens\"]\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"abbreviations\": abbreviations,\n",
    "        \"instruction_for_description\": make_instruction(\"description\"),\n",
    "        \"instruction_for_keywords\": make_instruction(\"keywords\"),\n",
    "        \"instruction_for_solution\": make_instruction(\"solution\"),\n",
    "    }"
   ],
   "id": "23f3b74c46df54ba",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Основная функция формирующая 3 инструктивных запроса с задачей и возвращающая переменную класса решения.",
   "id": "168da4ce46481e16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:27:18.487439Z",
     "start_time": "2025-05-12T11:27:18.481152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "  \n",
    "def chat_process(\n",
    "        model: AIModelAPI,\n",
    "        path_to_instruct_json: str,\n",
    "        path_to_task_txt: str,\n",
    "        multi_thread: bool = False\n",
    ") -> ProblemWithSolution:\n",
    "\n",
    "    def _call_request(request: LLMRequest) -> str:\n",
    "        result = model.get_response(request, max_tokens=request.max_tokens)\n",
    "        return result\n",
    "\n",
    "    def _check_json_and_txt(path_json: str, path_to_txt: str,) -> None:\n",
    "        shaped_path_task = path.splitext(path.basename(path_to_txt))\n",
    "        format_of_file_task = shaped_path_task[1]\n",
    "        if format_of_file_task != \".txt\":\n",
    "            raise ValueError(f\"Ожидаемый формат файла задачи - .txt, получен - {format_of_file_task}\")\n",
    "        \n",
    "        shaped_path_instruct = path.splitext(path.basename(path_json))\n",
    "        format_of_file_instruct = shaped_path_instruct[1]\n",
    "        if format_of_file_instruct != \".json\":\n",
    "            raise ValueError(f\"Ожидаемый формат файла инструкций - .json, получен - {format_of_file_task}\")\n",
    "    \n",
    "    \n",
    "    _check_json_and_txt(path_json=path_to_instruct_json, path_to_txt=path_to_task_txt)\n",
    "    \n",
    "    name = path.splitext(path.basename(path_to_task_txt))[0]\n",
    "    \n",
    "    general_task = load_data(path_to_task_txt)\n",
    "\n",
    "    instructions = load_instruction_file(path_to_instruct_json)\n",
    "    i_description = instructions[\"instruction_for_description\"]\n",
    "    i_keywords    = instructions[\"instruction_for_keywords\"]\n",
    "    i_solution    = instructions[\"instruction_for_solution\"]\n",
    "\n",
    "    r_description = LLMRequest(i_description, task=general_task)\n",
    "    r_keywords = LLMRequest(i_keywords,       task=general_task)\n",
    "    r_solution = LLMRequest(i_solution,       task=general_task)\n",
    "\n",
    "    tasks = {\n",
    "        \"description\": r_description,\n",
    "        \"keywords\":    r_keywords,\n",
    "        \"solution\":    r_solution\n",
    "    }\n",
    "\n",
    "    results: dict[str, str] = {}\n",
    "\n",
    "    if multi_thread:\n",
    "        with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "            future_to_label = {\n",
    "                executor.submit(_call_request, request): label\n",
    "                for label, request in tasks.items()\n",
    "            }\n",
    "            for future in as_completed(future_to_label):\n",
    "                label = future_to_label[future]\n",
    "                try:\n",
    "                    results[label] = future.result(timeout=30)\n",
    "                except Exception as e:\n",
    "                    results[label] = f\"Ошибка: {e}\"\n",
    "\n",
    "    else:\n",
    "        for label, request in tasks.items():\n",
    "            try:\n",
    "                results[label] = _call_request(request)\n",
    "            except Exception as e:\n",
    "                results[label] = f\"Ошибка: {e}\"\n",
    "\n",
    "\n",
    "    for key in tasks: results.setdefault(key, \"\")\n",
    "\n",
    "    return ProblemWithSolution(\n",
    "        name=name,\n",
    "        description=results[\"description\"],\n",
    "        keywords=results[\"keywords\"].split(),\n",
    "        solution=results[\"solution\"]\n",
    "    )\n"
   ],
   "id": "9463f57f95afcdb5",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Загрузка данных и библиотек и тестовый запуск.",
   "id": "722b7e6225a7e36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Загрузка конфигурационных данных.",
   "id": "8df223d0a137b090"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:27:18.766722Z",
     "start_time": "2025-05-12T11:27:18.520082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "path_to_task_txt = \"to_process/ПАКС ООО.txt\"\n",
    "path_to_instruct_json = \"solution/config/prompt_data.json\"\n",
    "\n",
    "model_url_DeepSeek = \"https://api.deepseek.com\"\n",
    "model_name_DeepSeek = \"deepseek-chat\"\n",
    "API_AI_DeepSeek = getenv(\"API_DS\")\n",
    "\n",
    "model_url_OpenAI = \"https://api.openai.com/v1\"\n",
    "model_name_OpenAI = \"gpt-4-turbo\"\n",
    "API_AI_OpenAI = getenv(\"API_GPT\")\n",
    "\n",
    "model_DeepSeek = AIModelAPI(API_AI_DeepSeek, model_url_DeepSeek, model_name_DeepSeek)\n",
    "model_OpenAI = AIModelAPI(API_AI_OpenAI, model_url_OpenAI, model_name_OpenAI)\n"
   ],
   "id": "ebe28f413295f870",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Запуск и отладочный вывод.",
   "id": "26e3860808cdbe19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:31:43.698150Z",
     "start_time": "2025-05-12T11:29:43.288782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "models = [model_DeepSeek, model_OpenAI]\n",
    "multi_thread_modes = [True, False]\n",
    "solutions = {\n",
    "    model_DeepSeek: None,\n",
    "    model_OpenAI: None,\n",
    "}\n",
    "separator = \"-\" * 50\n",
    "\n",
    "for model in models:\n",
    "    for mode in multi_thread_modes:\n",
    "        print(f\"\\n[TEST] Модель: {model.model_name} | Многопоточность: {mode}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        sol = chat_process(\n",
    "            model=model,\n",
    "            path_to_instruct_json=path_to_instruct_json,\n",
    "            path_to_task_txt=path_to_task_txt,\n",
    "            multi_thread=mode\n",
    "        )\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "        print(f\"[TEST] Время выполнения: {duration:.2f} секунд\\n\")\n",
    "\n",
    "        solutions[model] = sol"
   ],
   "id": "6929cc48f72589bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Модель: deepseek-chat | Многопоточность: True\n",
      "[TEST] Время выполнения: 27.16 секунд\n",
      "\n",
      "\n",
      "[TEST] Модель: deepseek-chat | Многопоточность: False\n",
      "[TEST] Время выполнения: 42.10 секунд\n",
      "\n",
      "\n",
      "[TEST] Модель: gpt-4-turbo | Многопоточность: True\n",
      "[TEST] Время выполнения: 25.73 секунд\n",
      "\n",
      "\n",
      "[TEST] Модель: gpt-4-turbo | Многопоточность: False\n",
      "[TEST] Время выполнения: 25.40 секунд\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "(<__main__.AIModelAPI object at 0x000001F210819400>, True)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 29\u001B[39m\n\u001B[32m     24\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m[TEST] Время выполнения: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mduration\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m секунд\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     26\u001B[39m         solutions[model] = sol\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m sol = \u001B[43msolutions\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_DeepSeek\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m]\u001B[49m\n\u001B[32m     30\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msol.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m              \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mseparator\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     31\u001B[39m       \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msol.description\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m       \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mseparator\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     32\u001B[39m       \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m \u001B[39m\u001B[33m'\u001B[39m.join(sol.keywords)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mseparator\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     33\u001B[39m       \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msol.solution\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m                         )\n",
      "\u001B[31mKeyError\u001B[39m: (<__main__.AIModelAPI object at 0x000001F210819400>, True)"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:32:33.523720Z",
     "start_time": "2025-05-12T11:32:33.521007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sol = solutions[model_DeepSeek]\n",
    "print(f\"{sol.name}              \\n{separator}\\n\"\n",
    "      f\"{sol.description}       \\n{separator}\\n\"\n",
    "      f\"{' '.join(sol.keywords)}\\n{separator}\\n\"\n",
    "      f\"{sol.solution}\"                         )"
   ],
   "id": "f52ae6894137d993",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ПАКС ООО              \n",
      "--------------------------------------------------\n",
      "**Проблема:** Необходимость повторной активации Скан-Архива после переноса терминального сервера.       \n",
      "--------------------------------------------------\n",
      "Скан-Архив, ERP, УПП, лицензия, конфигурация, подсистема, расширение, интеграция, база, дистрибутивы, инструкции, Microsoft VCRedist, библиотеки, программная компонента, шрифты, штрихкод, терминальный режим, терминальный сервер, лицензий, файл активации, реестр, руководство, видеоин\n",
      "--------------------------------------------------\n",
      "1. Убедиться, что лицензия Скан-Архива позволяет использование в ERP  \n",
      "2. Установить/обновить библиотеки Microsoft VCRedist:  \n",
      "   2.1. VCRedist 2012 (x86, x64) — https://example.com/vcredist2012  \n",
      "   2.2. VCRedist 2013 (x86, x64) — https://example.com/vcredist2013  \n",
      "   2.3. VCRedist 2015-2019 (x86, x64) — https://example.com/vcredist2017  \n",
      "3. Установить программную компоненту Скан-Архива — https://example.com/scanarchive  \n",
      "4. Установить шрифты для штрихкода из вложения (Fonts.zip)  \n",
      "5. Для терминального режима:  \n",
      "   5.1. Установить терминальный сервер лицензий — https://example.com/terminalserver  \n",
      "6. Сформировать файл \"Данные для создания ключа\" и отправить в техподдержку  \n",
      "7. Получить файл активации, запустить его и подтвердить внесение данных в реестр  \n",
      "8. Установить расширение Скан-Архива в ERP:  \n",
      "   8.1. Следовать разделу 4.1.2 руководства (\"Подключение СА как расширения\")  \n",
      "9. Использовать руководство пользователя и видеоинструкции для настройки:  \n",
      "   9.1. Настройка правил распознавания — https://example.com/recognition  \n",
      "   9.2. Настройка штрихкодирования — https://example.com/barcodes  \n",
      "   9.3. Печать этикеток — https://example.com/labels  \n",
      "10. При переносе терминального сервера:  \n",
      "    10.1. Отправить новый файл \"Данные для создания ключа\"  \n",
      "    10.2. Получить и активировать временный ключ (действует 3 дня)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:32:35.884223Z",
     "start_time": "2025-05-12T11:32:35.881645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sol = solutions[model_OpenAI]\n",
    "print(f\"{sol.name}              \\n{separator}\\n\"\n",
    "      f\"{sol.description}       \\n{separator}\\n\"\n",
    "      f\"{' '.join(sol.keywords)}\\n{separator}\\n\"\n",
    "      f\"{sol.solution}\"                         )"
   ],
   "id": "bf8ccf964f24059d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ПАКС ООО              \n",
      "--------------------------------------------------\n",
      "Переход на ERP: лицензия Скан-Архива действует независимо от конфигурации, требуется интеграция модуля.       \n",
      "--------------------------------------------------\n",
      "ERP, УПП, Скан-Архив, модуль, СА, лицензия, рабочие места, конфигурация, подсистема, расширение, интеграция, дистрибутивы, инструкции, установка, библиотеки, Microsoft, VCRedist, программная компонента, шрифты,\n",
      "--------------------------------------------------\n",
      "1. Скачайте и установите библиотеки Microsoft VCRedist:\n",
      "   1.1. vcredist 2012 (x86, x64) с официального сайта.\n",
      "   1.2. vcredist 2013 (x86, x64) с официального сайта.\n",
      "   1.3. vcredist 2017 (x86, x64) с официального сайта (Visual Studio 2015, 2017 и 2019).\n",
      "\n",
      "2. Установите терминальный сервер лицензий, если работаете в терминальном режиме.\n",
      "\n",
      "3. Установите программную компоненту Скан-Архива по предоставленной ссылке.\n",
      "\n",
      "4. Установите шрифты для вывода штрихкода из файла Fonts.zip.\n",
      "\n",
      "5. Сформируйте файл \"Данные для создания ключа\" и отправьте его в техподдержку для получения файла активации.\n",
      "\n",
      "6. Запустите полученный файл активации и подтвердите внесение данных в реестр.\n",
      "\n",
      "7. Подтвердите успешную активацию в техподдержку.\n",
      "\n",
      "8. Изучите руководство пользователя и видеоинструкции по установке и настройке Скан-Архива:\n",
      "   8.1. Видеоинструкция по активации Скан-Архива.\n",
      "   8.2. Видео по настройке правил распознавания по ключевым реквизитам.\n",
      "   8.3. Видео по настройке штрихкодирования.\n",
      "   8.4. Видео по печати этикеток.\n",
      "\n",
      "9. В случае необходимости повторной активации после переноса терминального сервера, отправьте новый файл с данными для создания ключа в техподдержку и повторите шаги 5-7.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Описание единой функции будет создано в отдельном проекте.\n",
    "\n",
    "### 5.1. Примечания и варианты для улучшения\n",
    "- Небольшие изменения и улучшения внесены в основную структуру проекта (в .ipynb их нет, как и великого смысла от них =));\n",
    "- Полагаю что в зависимости от нагрузки на сервера OpenAI и DeepSeek - имеем разную скорость ответа, особенно в распараллеленном режиме:\n",
    "    - OpenAI в пике 16 секунд;\n",
    "    - DeepSeek в пике 20 секунд;\n",
    "- Модель OpenAI лучше реагирует на ограничения по токенам;\n",
    "- Добавлю небольшой плюс в копилку к DeepSeek - работает без vpn.\n",
    "---\n",
    "- Инструктивно убрал сбор ссылок в решении ИИ. Логично было бы поправить инструкции на сохранение ссылок, которые не введут к личным хранилищам;\n",
    "- Имеют место быть и другие изменения в инструкциях. Но тут вопрос в задачах и в решении;\n",
    "- Изменить тип формата данных на вход. Скорее всего данные были собраны человеком, а не импортированы, поэтому отличным решением от меня было бы сделать извлечение откуда-то (например периодичный запрос к базе ТП, или ручное извлечение), ну или хотя бы стандартизировать input под .json;\n",
    "- Если добавить эвристический подсчет токенов с tiktoken (долго откладывал) для каждого запроса, то думаю точность ответов deepseek была бы гораздо выше. Плюсом в теории можно сэкономить баланс токенов;\n",
    "- Возможно хорошим изменением было бы сделать reranking для решения задачи. Отправить еще один запрос модели с инструкцией на проверку релевантности предыдущего решения (перепроверка). Но скорее всего для такой простой задачи (если я все правильно понял) это избыточно.\n"
   ],
   "id": "3ae3c6801badefff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c98222d71ffbff86"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
